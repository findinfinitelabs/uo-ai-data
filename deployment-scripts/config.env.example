# Healthcare AI Infrastructure Configuration
# Copy this file to config.env and customize as needed
# Usage: source config.env && ./deploy-all.sh

# ============================================
# EKS Cluster Configuration
# ============================================

# Name of the EKS cluster
CLUSTER_NAME="ollama-ai-cluster"

# AWS Region for deployment
AWS_REGION="us-east-1"

# Kubernetes version
K8S_VERSION="1.28"

# GPU instance type for AI workloads
# Options: g4dn.xlarge, g4dn.2xlarge, g4dn.4xlarge
# g4dn.xlarge: 1 GPU, 4 vCPUs, 16GB RAM (~$0.526/hour)
# g4dn.2xlarge: 1 GPU, 8 vCPUs, 32GB RAM (~$0.752/hour)
GPU_INSTANCE_TYPE="g4dn.xlarge"

# Number of GPU nodes
# More nodes = higher availability & capacity, but higher cost
# Default: 1 (small/medium cluster for development and testing)
GPU_NODE_COUNT=1

# ============================================
# Ollama Configuration
# ============================================

# Kubernetes namespace for Ollama
OLLAMA_NAMESPACE="ollama"

# Number of Ollama replicas
# More replicas = better load distribution
# Default: 1 (small/medium cluster)
OLLAMA_REPLICAS=1

# Persistent storage size for AI models
# Recommended: 50Gi minimum, 100Gi for multiple large models
STORAGE_SIZE="50Gi"

# Ollama version (use 'latest' or specific version)
OLLAMA_VERSION="latest"

# ============================================
# AWS Bedrock Configuration
# ============================================

# AWS Bedrock region (must support Bedrock)
# Supported regions: us-east-1, us-west-2, eu-west-1, ap-southeast-1, etc.
BEDROCK_REGION="us-east-1"

# Default Bedrock model ID
# Claude: anthropic.claude-3-haiku-20240307-v1:0
# Llama: meta.llama3-70b-instruct-v1:0
# Mistral: mistral.mistral-7b-instruct-v0:2
BEDROCK_MODEL="anthropic.claude-3-haiku-20240307-v1:0"

# Enable Bedrock? (true/false)
USE_BEDROCK="true"

# ============================================
# DynamoDB Configuration
# ============================================

# Prefix for DynamoDB table names
# Tables: {prefix}-patients, {prefix}-diagnoses, etc.
TABLE_PREFIX="healthcare"

# DynamoDB billing mode
# Options: PAY_PER_REQUEST, PROVISIONED
# PAY_PER_REQUEST recommended for variable workloads (~$5/month)
BILLING_MODE="PAY_PER_REQUEST"

# ============================================
# Integration Service Configuration
# ============================================

# Namespace for the query bridge
INTEGRATION_NAMESPACE="ollama"

# Docker image name
IMAGE_NAME="healthcare-ai-bridge"

# Image tag
IMAGE_TAG="latest"

# ============================================
# S3 Storage Configuration
# ============================================

# S3 bucket name for dataset publishing
# Leave empty to auto-generate: healthcare-ai-datasets-<timestamp>
# Must be globally unique
S3_BUCKET_NAME=""

# Enable S3 export in web UI
# When enabled, users can publish query results to S3
S3_EXPORT_ENABLED="true"

# ============================================
# Advanced Settings (Optional)
# ============================================

# AWS Profile (if using multiple AWS accounts)
# AWS_PROFILE="innovation-sandbox"

# Push images to ECR? (true/false)
# USE_ECR="true"

# Enable debug logging? (true/false)
# DEBUG="false"

# Timeout for deployments (in seconds)
# DEPLOYMENT_TIMEOUT=600

# ============================================
# Cost Optimization
# ============================================

# Use Spot Instances? (Requires manual cluster config modification)
# Can save ~70% but instances may be interrupted
# USE_SPOT_INSTANCES="false"

# Auto-shutdown schedule (CRON format)
# Example: Scale nodes to 0 at 6 PM daily
# AUTO_SHUTDOWN_CRON="0 18 * * *"

# ============================================
# Notes
# ============================================

# Estimated Daily Costs (with defaults):
# - 1x g4dn.xlarge GPU node: ~$12.62/day
# - 1x t3.medium general node: ~$1.01/day
# - EBS volumes: ~$0.40/day
# - 2x LoadBalancers: ~$1.20/day
# - DynamoDB (on-demand): ~$0.17/day (low usage)
# - S3 storage: ~$0.023/GB/month (~$0.001/GB/day)
# - Bedrock (pay-per-use): varies ($0.0008/1K input tokens for Claude Haiku)
# Total: ~$15-20/day base + usage-based costs (Bedrock, S3 transfer)

# To reduce costs:
# 1. Lower GPU_NODE_COUNT to 1 (~$13/day savings)
# 2. Lower OLLAMA_REPLICAS to 1
# 3. Use Ollama instead of Bedrock for development
# 4. Delete cluster when not in use
# 5. DynamoDB is already cost-optimized with PAY_PER_REQUEST

# To increase capacity:
# 1. Increase GPU_NODE_COUNT (3-4 for production)
# 2. Increase OLLAMA_REPLICAS to match nodes
# 3. Use larger GPU_INSTANCE_TYPE (g4dn.2xlarge)
# 4. Switch DynamoDB to PROVISIONED mode for predictable costs
# 5. Use Bedrock for production (managed, scalable, no infrastructure)
